{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from random import randint, choice, choices\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "def load_images(DIR):\n",
    "    fn = [os.path.join(DIR, f) for f in sorted(os.listdir(DIR)) if f.endswith(\".JPG\")]\n",
    "    return np.array([cv2.imread(f) for f in fn]), np.array(\n",
    "        [cv2.imread(f, 0) for f in fn]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris Corner Detection\n",
    "def harris_corner_detector(img, colimg, k=0.04, window_size=3, threshold=0.0025):\n",
    "    # Gaussian Blur over the image\n",
    "    img = cv2.GaussianBlur(img, (window_size, window_size), 0)\n",
    "\n",
    "    # Compute the gradients\n",
    "    Ix = cv2.Sobel(img, cv2.CV_64F, dx=0, dy=1, ksize=window_size)\n",
    "    Iy = cv2.Sobel(img, cv2.CV_64F, dx=1, dy=0, ksize=window_size)\n",
    "\n",
    "    # Compute the products of the gradients\n",
    "    IxIy = Ix * Iy\n",
    "    Ix2 = Ix**2\n",
    "    Iy2 = Iy**2\n",
    "\n",
    "    # Compute the sums of the products of the gradients\n",
    "    S2x = cv2.GaussianBlur(Ix2, (window_size, window_size), 0)\n",
    "    S2y = cv2.GaussianBlur(Iy2, (window_size, window_size), 0)\n",
    "    Sxy = cv2.GaussianBlur(IxIy, (window_size, window_size), 0)\n",
    "\n",
    "    # Harris Corner Response\n",
    "    det = (S2x * S2y) - (Sxy**2)\n",
    "    trace = S2x + S2y\n",
    "\n",
    "    R = det - k * (trace**2)\n",
    "\n",
    "    # Normalize\n",
    "    R /= R.max()\n",
    "\n",
    "    # Dilate\n",
    "    # Rd = cv2.dilate(R, None)\n",
    "    Rd = R\n",
    "\n",
    "    # Thresholding\n",
    "    R[Rd > threshold] = 255\n",
    "\n",
    "    # Non Max Suppression\n",
    "    R[Rd <= threshold] = 0\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NCC(f, g):\n",
    "    f_hat = f / np.linalg.norm(f)\n",
    "    g_hat = g / np.linalg.norm(g)\n",
    "\n",
    "    ncc = np.sum(f_hat * g_hat)\n",
    "    return ncc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showi(images):\n",
    "    for i, im in enumerate(images):\n",
    "        cv2.imshow(str(i), im)\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1157/1158 j=1695/1696\r"
     ]
    }
   ],
   "source": [
    "DIR = \"DanaHallWay1\"  # --> k=0.0025\n",
    "k = 0.0025\n",
    "ncc_thresh = 0.9995\n",
    "# DIR = \"DanaOffice\" #--> k=0.01 (?)\n",
    "# k = 0.01\n",
    "# ncc_thresh = 0.95\n",
    "col, gray = load_images(DIR)\n",
    "\n",
    "harris = []\n",
    "for i in range(len(col)):\n",
    "    R1 = harris_corner_detector(gray[i], col[i], threshold=k)\n",
    "    R2 = harris_corner_detector(gray[i + 1], col[i + 1], threshold=k)\n",
    "    break\n",
    "\n",
    "corner1 = np.where(R1 == 255)\n",
    "corner2 = np.where(R2 == 255)\n",
    "\n",
    "# List of coordinates of corners\n",
    "c1coords = list(zip(corner1[0], corner1[1]))\n",
    "c2coords = list(zip(corner2[0], corner2[1]))\n",
    "\n",
    "# samples = 600\n",
    "# c1coords = choices(c1coords, k=samples)\n",
    "# c2coords = choices(c2coords, k=samples)\n",
    "\n",
    "# Window size and padding for NCC\n",
    "window_size = 5\n",
    "pad = int((window_size - 1) / 2)\n",
    "\n",
    "# Pad gray images\n",
    "g1_pad = np.pad(gray[0], pad, \"constant\", constant_values=0)\n",
    "g2_pad = np.pad(gray[1], pad, \"constant\", constant_values=0)\n",
    "\n",
    "# Perform NCC\n",
    "# - Compare every corner detected in image 1 with every corner detected in image 2\n",
    "# - Store the pairs of corners with the highest correlation value\n",
    "corners = {}\n",
    "for i, corner1 in enumerate(c1coords):\n",
    "    # Image patch around corner 1\n",
    "    x1 = max(corner1[0] - pad, 0)\n",
    "    x2 = max(corner1[0] + pad + 1, window_size)\n",
    "    y1 = max(corner1[1] - pad, 0)\n",
    "    y2 = max(corner1[1] + pad + 1, window_size)\n",
    "    patch1 = g1_pad[\n",
    "        x1 : x2,\n",
    "        y1 : y2,\n",
    "    ]\n",
    "\n",
    "    maxNCC = -1\n",
    "    coords = None\n",
    "    for j, corner2 in enumerate(c2coords):\n",
    "        print(f\"i={i}/{len(c1coords)} j={j}/{len(c2coords)}\", end=\"\\r\")\n",
    "\n",
    "        # Image patch around corner 2\n",
    "        x1 = max(corner2[0] - pad, 0)\n",
    "        x2 = max(corner2[0] + pad + 1, window_size)\n",
    "        y1 = max(corner2[1] - pad, 0)\n",
    "        y2 = max(corner2[1] + pad + 1, window_size)\n",
    "        patch2 = g2_pad[\n",
    "            x1 : x2,\n",
    "            y1 : y2,\n",
    "        ]\n",
    "        # Calculate NCC using image patches\n",
    "        ncc = NCC(patch1, patch2)\n",
    "        # If this NCC is the new max, store it and the coords of the corner\n",
    "        if ncc > maxNCC:\n",
    "            maxNCC = ncc\n",
    "            coords = corner2[0], corner2[1]\n",
    "\n",
    "    # Break earlier for testing\n",
    "    # if i > 100:\n",
    "    #     break\n",
    "\n",
    "    # Threshold\n",
    "    if maxNCC < ncc_thresh:\n",
    "        continue\n",
    "\n",
    "    # Store corner pair with highest NCC\n",
    "    corners[(corner1[0], corner1[1])] = coords\n",
    "    # Color the corners in the images\n",
    "    # col[0][corner1[0], corner1[1]] = [0, 0, 255]\n",
    "    # col[1][coords[0], coords[1]] = [0, 0, 255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corners: dict[tuple[int, int]: tuple[int, int]]\n",
    "def drawCorrelationLines(image1, image2, corners):\n",
    "    # Concatenate the two images\n",
    "    vis = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    # Draw lines between correlated corners\n",
    "    for key, value in corners.items():\n",
    "        r = randint(0, 255)\n",
    "        g = randint(0, 255)\n",
    "        b = randint(0, 255)\n",
    "        start_y, start_x = key\n",
    "        end_y, end_x = value\n",
    "        end_x = int(end_x + vis.shape[1]/2)\n",
    "        end = (end_x, end_y)\n",
    "        start = (start_x, start_y)\n",
    "        cv2.line(vis, start, end, (b, g, r), 1)\n",
    "\n",
    "    showi([vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawCorrelationLines(col[0], col[1], corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 {(4, 364): (7, 252), (5, 364): (7, 252), (6, 363): (8, 251), (15, 441): (23, 324), (17, 441): (24, 324), (17, 442): (24, 325), (18, 441): (25, 324), (18, 442): (25, 325), (19, 441): (26, 324), (32, 487): (41, 364), (33, 441): (39, 324), (34, 441): (40, 324), (34, 442): (40, 325), (35, 441): (40, 325), (35, 442): (41, 324), (36, 441): (41, 325), (36, 442): (42, 324), (37, 441): (42, 325), (37, 442): (43, 324), (38, 441): (43, 325), (38, 442): (44, 325), (65, 197): (59, 81), (66, 196): (60, 80), (99, 175): (94, 58), (150, 148): (149, 28), (153, 182): (152, 66), (153, 183): (152, 67), (154, 182): (153, 66), (154, 183): (153, 67), (154, 184): (153, 68), (155, 159): (154, 40), (159, 155): (159, 36), (160, 154): (160, 35), (160, 155): (159, 36), (161, 468): (159, 348), (161, 469): (159, 348), (162, 467): (160, 348), (170, 485): (167, 364), (171, 455): (168, 337), (171, 467): (168, 348), (171, 468): (168, 349), (172, 462): (169, 344), (172, 463): (169, 343), (173, 462): (170, 343), (173, 463): (170, 343), (177, 451): (174, 334), (273, 454): (263, 338), (274, 453): (264, 337), (274, 454): (264, 338), (275, 454): (265, 338), (276, 454): (266, 338), (276, 472): (265, 354), (276, 473): (264, 355), (276, 474): (264, 356), (276, 476): (264, 357), (276, 484): (264, 364), (277, 482): (265, 362), (277, 484): (264, 364), (278, 482): (264, 362), (294, 367): (288, 257)}\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "N = 4\n",
    "\n",
    "inliers = {}\n",
    "outliers = {}\n",
    "max_inliers = 0\n",
    "\n",
    "# TODO: This is kinda arbitrary - trial and error maybe\n",
    "dist_threshold = 4\n",
    "\n",
    "for i in range(k):\n",
    "    # print(f\"===== Iteration #{i + 1}\")\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "\n",
    "    set_inliers = {}\n",
    "    set_outliers = {}\n",
    "\n",
    "    num_inliers = 0\n",
    "    num_outliers = 0\n",
    "\n",
    "    # Sample the minimal number of points needed to estimate a homography (4 pts)\n",
    "    for _ in range(N):\n",
    "        pt1 = choice(list(corners.keys()))\n",
    "        pt2 = list(corners[pt1])\n",
    "        pt1 = list(pt1)\n",
    "        points1.append(pt1)\n",
    "        points2.append(pt2)\n",
    "    points1 = np.asarray(points1)\n",
    "    points2 = np.asarray(points2)\n",
    "\n",
    "    # Compute homography matrix using these points\n",
    "    h, status = cv2.findHomography(points1, points2)\n",
    "    try:\n",
    "        h_inv = np.linalg.pinv(h)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for corner1, corner2 in corners.items():\n",
    "        # Estimate point using homography\n",
    "        pt1 = np.array([corner1[0], corner1[1], 1])\n",
    "        pt2 = np.array([corner2[0], corner2[1], 1])\n",
    "        res = np.matmul(h, pt1)\n",
    "        res = (res[:2]/res[2]).astype(int)\n",
    "        dist = np.linalg.norm(res-corner2)\n",
    "\n",
    "        # Check if outlier\n",
    "        if dist > dist_threshold:\n",
    "            set_outliers[tuple(corner1)] = tuple(corner2)\n",
    "            num_outliers += 1\n",
    "            continue\n",
    "\n",
    "        # Store inlier\n",
    "        set_inliers[tuple(corner1)] = tuple(corner2)\n",
    "        num_inliers += 1\n",
    "\n",
    "    # Check if this homography produced the new largest set of inliers\n",
    "    if num_inliers > max_inliers:\n",
    "        max_inliers = num_inliers\n",
    "        inliers = set_inliers\n",
    "        outliers = set_outliers\n",
    "\n",
    "print(max_inliers, inliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute least-squares homography from ALL the inliers in the largest set of inliers\n",
    "points1 = np.array([*inliers.keys()])\n",
    "points2 = np.array([*inliers.values()])\n",
    "H, status = cv2.findHomography(points1, points2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(inliers))\n",
    "drawCorrelationLines(col[0], col[1], inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(outliers))\n",
    "drawCorrelationLines(col[0], col[1], outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornersH = {}\n",
    "\n",
    "im1pt1, im1pt2 = choices(list(inliers.keys()), k=2)\n",
    "im2pt1, im2pt2 = inliers[im1pt1], inliers[im1pt2]\n",
    "\n",
    "sticher=cv2.Stitcher.create()\n",
    "result = sticher.stitch((col[0], col[1], col[2]))\n",
    "\n",
    "showi([col[0], col[1], result[1]])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
