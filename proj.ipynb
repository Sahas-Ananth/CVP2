{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyimagesearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ELIPC~1\\AppData\\Local\\Temp/ipykernel_19600/570534627.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyimagesearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpanorama\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStitcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyimagesearch'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "import os\n",
    "import cv2\n",
    "from random import randint, choice, choices\n",
    "from math import sqrt\n",
    "from skimage import transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "def load_images(DIR):\n",
    "    fn = [os.path.join(DIR, f) for f in sorted(os.listdir(DIR)) if f.endswith(\".JPG\")]\n",
    "    return np.array([cv2.imread(f) for f in fn]), np.array(\n",
    "        [cv2.imread(f, 0) for f in fn]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris Corner Detection\n",
    "def harris_corner_detector(img, colimg, k=0.04, window_size=3, threshold=0.0025):\n",
    "    # Gaussian Blur over the image\n",
    "    img = cv2.GaussianBlur(img, (window_size, window_size), 0)\n",
    "\n",
    "    # Compute the gradients\n",
    "    Ix = cv2.Sobel(img, cv2.CV_64F, dx=0, dy=1, ksize=window_size)\n",
    "    Iy = cv2.Sobel(img, cv2.CV_64F, dx=1, dy=0, ksize=window_size)\n",
    "\n",
    "    # Compute the products of the gradients\n",
    "    IxIy = Ix * Iy\n",
    "    Ix2 = Ix**2\n",
    "    Iy2 = Iy**2\n",
    "\n",
    "    # Compute the sums of the products of the gradients\n",
    "    S2x = cv2.GaussianBlur(Ix2, (window_size, window_size), 0)\n",
    "    S2y = cv2.GaussianBlur(Iy2, (window_size, window_size), 0)\n",
    "    Sxy = cv2.GaussianBlur(IxIy, (window_size, window_size), 0)\n",
    "\n",
    "    # Harris Corner Response\n",
    "    det = (S2x * S2y) - (Sxy**2)\n",
    "    trace = S2x + S2y\n",
    "\n",
    "    R = det - k * (trace**2)\n",
    "\n",
    "    # Normalize\n",
    "    R /= R.max()\n",
    "\n",
    "    # Dilate\n",
    "    # Rd = cv2.dilate(R, None)\n",
    "    Rd = R\n",
    "\n",
    "    # Thresholding\n",
    "    R[Rd > threshold] = 255\n",
    "\n",
    "    # Non Max Suppression\n",
    "    R[Rd <= threshold] = 0\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NCC(f, g):\n",
    "    f_hat = f / np.linalg.norm(f)\n",
    "    g_hat = g / np.linalg.norm(g)\n",
    "\n",
    "    ncc = np.sum(f_hat * g_hat)\n",
    "    return ncc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(col, gray):\n",
    "    for i in range(len(col)):\n",
    "        cv2.imshow(\"{i}\", col[i])\n",
    "        cv2.imshow(\"G{i}\", gray[i])\n",
    "        if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            if 0xFF == ord(\"e\"):\n",
    "                break\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1157/1158 j=1695/1696\r"
     ]
    }
   ],
   "source": [
    "DIR = \"DanaHallWay1\"  # --> k=0.0025\n",
    "# DIR = \"DanaOffice\" #--> k=0.01 (?)\n",
    "col, gray = load_images(DIR)\n",
    "\n",
    "harris = []\n",
    "for i in range(len(col)):\n",
    "    R1 = harris_corner_detector(gray[i], col[i])\n",
    "    R2 = harris_corner_detector(gray[i + 1], col[i + 1])\n",
    "    break\n",
    "\n",
    "corner1 = np.where(R1 == 255)\n",
    "corner2 = np.where(R2 == 255)\n",
    "\n",
    "# List of coordinates of corners\n",
    "c1coords = list(zip(corner1[0], corner1[1]))\n",
    "c2coords = list(zip(corner2[0], corner2[1]))\n",
    "\n",
    "# Window size and padding for NCC\n",
    "window_size = 5\n",
    "pad = int((window_size - 1) / 2)\n",
    "\n",
    "# Pad gray images\n",
    "g1_pad = np.pad(gray[0], pad, \"constant\", constant_values=0)\n",
    "g2_pad = np.pad(gray[1], pad, \"constant\", constant_values=0)\n",
    "\n",
    "# Perform NCC\n",
    "# - Compare every corner detected in image 1 with every corner detected in image 2\n",
    "# - Store the pairs of corners with the highest correlation value\n",
    "corners = {}\n",
    "for i, corner1 in enumerate(c1coords):\n",
    "    # Image patch around corner 1\n",
    "    x1 = max(corner1[0] - pad, 0)\n",
    "    x2 = max(corner1[0] + pad + 1, window_size)\n",
    "    y1 = max(corner1[1] - pad, 0)\n",
    "    y2 = max(corner1[1] + pad + 1, window_size)\n",
    "    patch1 = g1_pad[\n",
    "        x1 : x2,\n",
    "        y1 : y2,\n",
    "    ]\n",
    "\n",
    "    maxNCC = -1\n",
    "    coords = None\n",
    "    for j, corner2 in enumerate(c2coords):\n",
    "        print(f\"i={i}/{len(c1coords)} j={j}/{len(c2coords)}\", end=\"\\r\")\n",
    "\n",
    "        # Image patch around corner 2\n",
    "        x1 = max(corner2[0] - pad, 0)\n",
    "        x2 = max(corner2[0] + pad + 1, window_size)\n",
    "        y1 = max(corner2[1] - pad, 0)\n",
    "        y2 = max(corner2[1] + pad + 1, window_size)\n",
    "        patch2 = g2_pad[\n",
    "            x1 : x2,\n",
    "            y1 : y2,\n",
    "        ]\n",
    "        # Calculate NCC using image patches\n",
    "        ncc = NCC(patch1, patch2)\n",
    "        # If this NCC is the new max, store it and the coords of the corner\n",
    "        if ncc > maxNCC:\n",
    "            maxNCC = ncc\n",
    "            coords = corner2[0], corner2[1]\n",
    "\n",
    "    # Break earlier for testing\n",
    "    # if i > 100:\n",
    "    #     break\n",
    "\n",
    "    # Threshold\n",
    "    if maxNCC < 0.9995:\n",
    "        continue\n",
    "\n",
    "    # Store corner pair with highest NCC\n",
    "    corners[(corner1[0], corner1[1])] = coords\n",
    "    # Color the corners in the images\n",
    "    col[0][corner1[0], corner1[1]] = [0, 0, 255]\n",
    "    col[1][coords[0], coords[1]] = [0, 0, 255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corners: dict[tuple[int, int]: tuple[int, int]]\n",
    "def drawCorrelationLines(image1, image2, corners):\n",
    "    # Concatenate the two images\n",
    "    vis = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    # Draw lines between correlated corners\n",
    "    for key, value in corners.items():\n",
    "        r = randint(0, 255)\n",
    "        g = randint(0, 255)\n",
    "        b = randint(0, 255)\n",
    "        start_y, start_x = key\n",
    "        end_y, end_x = value\n",
    "        end_x = int(end_x + vis.shape[1]/2)\n",
    "        end = (end_x, end_y)\n",
    "        start = (start_x, start_y)\n",
    "        cv2.line(vis, start, end, (b, g, r), 1)\n",
    "\n",
    "    show([vis], [vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawCorrelationLines(col[0], col[1], corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 {(4, 364): (7, 252), (5, 364): (7, 252), (6, 363): (8, 251), (15, 441): (23, 324), (17, 441): (24, 324), (17, 442): (24, 325), (18, 441): (25, 324), (18, 442): (25, 325), (19, 441): (26, 324), (32, 487): (41, 364), (33, 441): (39, 324), (34, 441): (40, 324), (34, 442): (40, 325), (35, 441): (40, 325), (35, 442): (41, 324), (36, 441): (41, 325), (36, 442): (42, 324), (37, 441): (42, 325), (37, 442): (43, 324), (38, 441): (43, 325), (38, 442): (44, 325), (65, 197): (59, 81), (66, 196): (60, 80), (99, 175): (94, 58), (150, 148): (149, 28), (153, 182): (152, 66), (153, 183): (152, 67), (154, 182): (153, 66), (154, 183): (153, 67), (154, 184): (153, 68), (155, 159): (154, 40), (159, 155): (159, 36), (160, 154): (160, 35), (160, 155): (159, 36), (161, 468): (159, 348), (161, 469): (159, 348), (162, 467): (160, 348), (170, 485): (167, 364), (171, 455): (168, 337), (171, 467): (168, 348), (171, 468): (168, 349), (172, 462): (169, 344), (172, 463): (169, 343), (173, 462): (170, 343), (173, 463): (170, 343), (177, 451): (174, 334), (273, 454): (263, 338), (274, 453): (264, 337), (274, 454): (264, 338), (275, 454): (265, 338), (276, 454): (266, 338), (276, 476): (264, 357), (294, 367): (288, 257)}\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "N = 4\n",
    "\n",
    "inliers = {}\n",
    "outliers = {}\n",
    "max_inliers = 0\n",
    "\n",
    "# TODO: This is kinda arbitrary - trial and error maybe\n",
    "dist_threshold = 4\n",
    "\n",
    "for i in range(k):\n",
    "    # print(f\"===== Iteration #{i + 1}\")\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "\n",
    "    set_inliers = {}\n",
    "    set_outliers = {}\n",
    "\n",
    "    num_inliers = 0\n",
    "    num_outliers = 0\n",
    "\n",
    "    # Sample the minimal number of points needed to estimate a homography (4 pts)\n",
    "    for _ in range(N):\n",
    "        pt1 = choice(list(corners.keys()))\n",
    "        pt2 = list(corners[pt1])\n",
    "        pt1 = list(pt1)\n",
    "        points1.append(pt1)\n",
    "        points2.append(pt2)\n",
    "    points1 = np.asarray(points1)\n",
    "    points2 = np.asarray(points2)\n",
    "\n",
    "    # Compute homography matrix using these points\n",
    "    h, status = cv2.findHomography(points1, points2)\n",
    "    try:\n",
    "        h_inv = np.linalg.pinv(h)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for corner1, corner2 in corners.items():\n",
    "        # print(corner1, corner2)\n",
    "        # Estimate corner1 using homography\n",
    "        mat1 = np.array([corner2[0], corner2[1], 1])\n",
    "        res1 = np.matmul(h_inv, mat1)\n",
    "        res1 = (res1[:2]/res1[2]).astype(int)\n",
    "        dist1 = dist(res1, corner1)\n",
    "\n",
    "        # Estimate corner2 using homography\n",
    "        mat2 = np.array([corner1[0], corner1[1], 1])\n",
    "        res2 = np.matmul(h, mat2)\n",
    "        res2 = (res2[:2]/res2[2]).astype(int)\n",
    "        dist2 = dist(res2, corner2)\n",
    "\n",
    "        # Check if outlier\n",
    "        if dist1 > dist_threshold or dist2 > dist_threshold:\n",
    "            set_outliers[tuple(corner1)] = tuple(corner2)\n",
    "            num_outliers += 1\n",
    "            continue\n",
    "\n",
    "        # Store inlier\n",
    "        set_inliers[tuple(corner1)] = tuple(corner2)\n",
    "        num_inliers += 1\n",
    "\n",
    "    # Check if this homography produced the new largest set of inliers\n",
    "    if num_inliers > max_inliers:\n",
    "        max_inliers = num_inliers\n",
    "        inliers = set_inliers\n",
    "        outliers = set_outliers\n",
    "\n",
    "print(max_inliers, inliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute least-squares homography from ALL the inliers in the largest set of inliers\n",
    "points1 = np.array([*inliers.keys()])\n",
    "points2 = np.array([*inliers.values()])\n",
    "H, status = cv2.findHomography(points1, points2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawCorrelationLines(col[0], col[1], inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawCorrelationLines(col[0], col[1], outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show3(im1, im2, im3):\n",
    "    cv2.imshow(\"1\", im1)\n",
    "    cv2.imshow(\"2\", im2)\n",
    "    cv2.imshow(\"3\", im3)\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornersH = {}\n",
    "\n",
    "im1pt1, im1pt2 = choices(list(inliers.keys()), k=2)\n",
    "im2pt1, im2pt2 = inliers[im1pt1], inliers[im1pt2]\n",
    "\n",
    "sticher=cv2.Stitcher.create()\n",
    "result = sticher.stitch((col[0], col[1], col[2]))\n",
    "\n",
    "show3(col[0], col[1], result[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warp one image onto the other one, blending overlapping pixels together to create\n",
    "a single image that shows the union of all pixels from both input images. You can\n",
    "choose which of the images to warp. The steps are as follows:\n",
    "\n",
    "A. Determine how big to make the final output image so that it contains the union\n",
    "of all pixels in the two images.\n",
    "\n",
    "B. Copy the image that does not have to be warped into the appropriate location\n",
    "in the output.\n",
    "\n",
    "C. Warp the other image into the output image based on the estimated homography\n",
    "(or its inverse). You can use matlab functions if you want or write your own\n",
    "warping function.\n",
    "\n",
    "D. Use any of the blending schemes we will discuss in class to blend pixels in the\n",
    "area of overlap between both images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = col[0].shape[0]\n",
    "# y = col[0].shape[1]\n",
    "\n",
    "# output = np.zeros((x + 100, 2 * y + 100, 3))\n",
    "\n",
    "# image =  col[0].astype('uint8')\n",
    "# output =  output.astype('uint8')\n",
    "\n",
    "# print(output.shape)\n",
    "# print(output[10:x + 10, 10:y + 10].shape)\n",
    "# print(image.shape)\n",
    "\n",
    "# output[10:x + 10, 10:y + 10] += image\n",
    "\n",
    "# output =  output.astype('float64')\n",
    "# output /= 255\n",
    "\n",
    "# stitchy=cv2.Stitcher.create()\n",
    "# transformed = transform.warp(col[1], H)\n",
    "\n",
    "# print(transformed.dtype)\n",
    "# show([output],[transformed])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
